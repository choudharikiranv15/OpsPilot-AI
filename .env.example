# OpsPilot Environment Configuration
# Copy this file to .env and fill in your API keys

# ============================================
# LLM Providers (Choose at least ONE)
# ============================================

# Option 1: Google Gemini (FREE tier - 15 req/min)
# Get key: https://aistudio.google.com/
# GOOGLE_API_KEY=your-google-api-key-here

# Option 2: OpenRouter (FREE models available)
# Get key: https://openrouter.ai/
# OPENROUTER_API_KEY=your-openrouter-api-key-here

# Option 3: HuggingFace (FREE tier - 1000 req/day)
# Get token: https://huggingface.co/settings/tokens
# HUGGINGFACE_API_KEY=your-huggingface-token-here

# Option 4: Ollama (Local - No API key needed)
# Install: curl -fsSL https://ollama.ai/install.sh | sh
# Pull model: ollama pull llama3
# No configuration needed!

# ============================================
# AWS Credentials (for S3/CloudWatch logs)
# ============================================

# AWS_ACCESS_KEY_ID=your-aws-access-key
# AWS_SECRET_ACCESS_KEY=your-aws-secret-key
# AWS_DEFAULT_REGION=us-east-1

# ============================================
# OpsPilot Settings
# ============================================

# Prefer local LLM (Ollama) over cloud providers
# OPSPILOT_PREFER_LOCAL=true

# LLM inference timeout (seconds)
# OPSPILOT_LLM_TIMEOUT=60

# ============================================
# Development/Testing
# ============================================

# DEBUG=False
# REDIS_URL=redis://localhost:6379
