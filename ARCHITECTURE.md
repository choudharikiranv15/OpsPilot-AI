# OpsPilot Architecture

> High-level design documentation for the OpsPilot agentic AI system

---

## Table of Contents

- [Overview](#overview)
- [Core Principles](#core-principles)
- [System Architecture](#system-architecture)
- [Agent Design](#agent-design)
- [Data Flow](#data-flow)
- [State Management](#state-management)
- [LLM Integration](#llm-integration)
- [Design Decisions](#design-decisions)
- [Future Enhancements](#future-enhancements)

---

## Overview

OpsPilot implements a **multi-agent agentic architecture** where specialized AI agents collaborate to diagnose and resolve runtime issues. The system follows a clear workflow: gather context → generate hypothesis → verify with evidence → suggest fixes.

### Key Components

```
┌─────────────────────────────────────────────────────────────┐
│                         CLI Layer                            │
│                      (User Interface)                        │
└───────────────────────────┬─────────────────────────────────┘
                            │
┌───────────────────────────▼─────────────────────────────────┐
│                    Graph Engine                              │
│              (Orchestrates Agent Workflow)                   │
└───────────────────────────┬─────────────────────────────────┘
                            │
        ┌───────────────────┼───────────────────┐
        │                   │                   │
        ▼                   ▼                   ▼
┌──────────────┐    ┌──────────────┐    ┌──────────────┐
│   Planner    │───▶│  Verifier    │───▶│    Fixer     │
│    Agent     │    │    Agent     │    │    Agent     │
└──────────────┘    └──────────────┘    └──────────────┘
        │                   │                   │
        └───────────────────┴───────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                    Context Layer                             │
│  (Logs, Env, Docker, Dependencies, Project Structure)       │
└─────────────────────────────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                      Tools Layer                             │
│         (Evidence Collection & Analysis Utilities)           │
└─────────────────────────────────────────────────────────────┘
```

---

## Core Principles

### 1. **Safety First**
- All fix suggestions are **dry-run only**
- Never automatically applies changes to user's code
- Provides clear rationale for every suggestion

### 2. **Evidence-Based Reasoning**
- Decisions backed by concrete evidence (logs, configs, etc.)
- Confidence scoring (0.0 - 1.0) for transparency
- Threshold-based decision making (confidence ≥ 0.6 required for fixes)

### 3. **Modularity & Extensibility**
- Each agent is independent and focused
- Context modules are pluggable
- Easy to add new agents or data sources

### 4. **Local-First**
- Uses local LLM (Ollama) - no cloud dependencies
- Privacy-aware: no sensitive data sent externally
- Works completely offline

### 5. **Learning & Memory**
- Maintains history of past issues
- Detects similar problems in future runs
- Improves diagnosis speed over time

---

## System Architecture

### Architecture Pattern: Multi-Agent State Machine

OpsPilot uses a **state-based workflow** where each agent transforms the system state:

```python
State = {
    project_root: str,
    context: dict,           # Gathered from multiple sources
    hypothesis: str,         # Generated by Planner
    confidence: float,       # Updated by Verifier
    evidence: dict,          # Collected by Verifier
    suggestions: list,       # Generated by Fixer
    terminated: bool         # Workflow control flag
}
```

### Workflow States

1. **Initial State**: Empty state with only `project_root`
2. **Context Collected**: State populated with logs, env, deps, etc.
3. **Hypothesis Formed**: Planner adds hypothesis and initial confidence
4. **Evidence Gathered**: Verifier collects concrete evidence
5. **Hypothesis Verified**: Verifier updates confidence based on evidence
6. **Fixes Suggested** (if confidence ≥ 0.6): Fixer generates suggestions
7. **Terminal State**: Workflow completes

---

## Agent Design

### 1. Planner Agent (`agents/planner.py`)

**Responsibility**: Analyze project context and generate hypotheses about root causes

**Input**: Project context (logs, env vars, dependencies, structure)

**Output**:
```json
{
  "hypothesis": "Redis connection issue caused by network timeout",
  "confidence": 0.8,
  "possible_causes": ["Network latency", "Redis server down"],
  "required_checks": ["Verify Redis connectivity", "Check network logs"]
}
```

**LLM Prompt Strategy**:
- Role: Senior Site Reliability Engineer
- Task: Analyze context and form hypothesis
- Output: Strict JSON format (no explanatory text)
- Context Summarization: Limits logs to 2000 chars, deps to 20 items (token optimization)

**Key Features**:
- Context summarization to reduce LLM token usage
- Robust JSON extraction (handles LLM adding explanatory text)
- 120-second timeout with error handling

---

### 2. Verifier Agent (`agents/verifier.py`)

**Responsibility**: Validate hypotheses using concrete evidence

**Input**:
- Hypothesis from Planner
- Evidence collected from tools

**Output**:
```json
{
  "supported": true,
  "confidence": 0.8,
  "reason": "Log errors and Redis usage confirm connection issue"
}
```

**Evidence Types**:
- `log_errors`: Error counts by type (ERROR, Timeout, Exception)
- `missing_env`: Required environment variables not found
- `uses_redis`: Boolean flag for Redis dependency
- More evidence types can be added via tools

**Decision Logic**:
- Confidence ≥ 0.6 → Proceed to Fixer
- Confidence < 0.6 → Terminate workflow (not enough certainty)

---

### 3. Fixer Agent (`agents/fixer.py`)

**Responsibility**: Generate safe, actionable fix suggestions

**Input**:
- Hypothesis
- Evidence

**Output**:
```json
{
  "suggestions": [
    {
      "file": ".env",
      "diff": "--- a/.env\n+++ b/.env\n-REDIS_TIMEOUT=1\n+REDIS_TIMEOUT=5",
      "rationale": "Increase timeout to reduce transient errors"
    }
  ]
}
```

**Fix Strategy**:
1. **Domain-Specific Fixes** (hardcoded templates)
   - Redis timeout adjustment
   - Redis connection pooling
   - More domains can be added (PostgreSQL, MongoDB, etc.)

2. **LLM-Generated Fixes** (fallback)
   - If no template matches, use LLM to generate custom suggestions
   - Output as unified diff format

**Safety Guarantees**:
- All fixes shown as diffs (preview before apply)
- Rationale provided for each suggestion
- User must manually apply changes

---

## Data Flow

### Complete Execution Flow

```
User runs: opspilot analyze
          │
          ▼
┌─────────────────────────┐
│  1. Initialize State    │
│     (project_root)      │
└──────────┬──────────────┘
           │
           ▼
┌─────────────────────────┐
│  2. Collect Context     │
│     - Scan logs         │
│     - Read .env         │
│     - Parse deps        │
│     - Check Docker      │
│     - Map structure     │
└──────────┬──────────────┘
           │
           ▼
┌─────────────────────────┐
│  3. Planner Agent       │
│     - Summarize context │
│     - Call LLM          │
│     - Extract JSON      │
│     - Form hypothesis   │
└──────────┬──────────────┘
           │
           ▼
┌─────────────────────────┐
│  4. Collect Evidence    │
│     - Analyze logs      │
│     - Check env vars    │
│     - Detect deps       │
└──────────┬──────────────┘
           │
           ▼
┌─────────────────────────┐
│  5. Verifier Agent      │
│     - Match evidence    │
│     - Update confidence │
│     - Decide next step  │
└──────────┬──────────────┘
           │
           ▼
      Confidence ≥ 0.6?
           │
    ┌──────┴──────┐
    │ YES         │ NO
    ▼             ▼
┌─────────────┐  ┌─────────────┐
│ 6. Fixer    │  │ 7. Terminate│
│    Agent    │  │    (Low     │
│    - Gen    │  │  Confidence)│
│      fixes  │  └─────────────┘
└──────┬──────┘
       │
       ▼
┌─────────────────────────┐
│  8. Save to Memory      │
│     (~/.opspilot_mem)   │
└──────────┬──────────────┘
           │
           ▼
    Display Results
```

---

## State Management

### AgentState Dataclass

```python
@dataclass
class AgentState:
    project_root: str
    context: Dict[str, Any] = field(default_factory=dict)
    hypothesis: Optional[str] = None
    confidence: float = 0.0
    evidence: Dict[str, Any] = field(default_factory=dict)
    suggestions: List[Dict[str, Any]] = field(default_factory=list)
    checks_remaining: List[str] = field(default_factory=list)
    iteration: int = 0
    terminated: bool = False
```

### State Transitions

Each agent is implemented as a **pure function** that takes state and returns updated state:

```python
def planner_node(state: AgentState) -> AgentState:
    result = plan(state.context)
    state.hypothesis = result.get("hypothesis")
    state.confidence = result.get("confidence", 0.0)
    state.iteration += 1
    return state

def verifier_node(state: AgentState) -> AgentState:
    state.evidence = collect_evidence(state.context)
    verdict = verify(state.hypothesis, state.evidence)
    state.confidence = verdict.get("confidence", state.confidence)
    return state

def fixer_node(state: AgentState) -> AgentState:
    if state.confidence >= CONFIDENCE_THRESHOLD:
        fixes = suggest(state.hypothesis, state.evidence)
        state.suggestions = fixes.get("suggestions", [])
    return state
```

### Workflow Termination

The workflow terminates when:
1. Confidence ≥ 0.6 and fixes are generated, OR
2. Confidence < 0.6 (insufficient evidence), OR
3. Maximum iterations reached (safety limit)

---

## LLM Integration

### Ollama Integration Strategy

OpsPilot uses **Ollama** (local LLM runtime) with **Llama 3** model:

**Why Ollama?**
- ✅ Runs locally - no cloud API costs
- ✅ Privacy-preserving - no data sent externally
- ✅ Works offline
- ✅ Fast inference for smaller models
- ✅ Easy to switch models (llama3, mistral, phi, etc.)

### Prompt Engineering Techniques

#### 1. Structured Output Prompting
```python
SYSTEM_PROMPT = """
You are a senior site reliability engineer.
Your task is to analyze project context and form a hypothesis.

CRITICAL: Your response must be ONLY valid JSON with this exact format:
{
  "hypothesis": "...",
  "confidence": 0.0,
  "possible_causes": ["..."],
  "required_checks": ["..."]
}

Do not include any text before the opening { or after the closing }.
"""
```

#### 2. Context Summarization (Token Optimization)
```python
summarized_context = {
    "logs": context.get("logs", "")[:2000],           # Limit to 2000 chars
    "env": list(context.get("env", {}).keys()),      # Only var names
    "dependencies": context.get("dependencies", [])[:20],  # Top 20
    "structure": str(context.get("structure", ""))[:1000]  # Limit
}
```

#### 3. Robust JSON Extraction
```python
# LLMs often add explanatory text before/after JSON
# Extract JSON between first { and last }
start_idx = raw_output.find('{')
end_idx = raw_output.rfind('}')
if start_idx != -1 and end_idx != -1:
    json_str = raw_output[start_idx:end_idx + 1]
    result = json.loads(json_str)
```

#### 4. Error Handling & Timeouts
- 120-second timeout per LLM call (prevents hanging)
- Fallback responses on JSON parsing errors
- Informative error messages for debugging

---

## Design Decisions

### Why Multi-Agent Instead of Single LLM Call?

**Pros**:
- ✅ **Separation of concerns**: Each agent has a focused task
- ✅ **Easier to debug**: Can inspect state between agents
- ✅ **Modular**: Can replace/upgrade individual agents
- ✅ **Testable**: Each agent can be tested independently
- ✅ **Iterative refinement**: Can add feedback loops later

**Cons**:
- ❌ More LLM calls (higher latency)
- ❌ More complex state management

**Decision**: Multi-agent for maintainability and extensibility

---

### Why Confidence Threshold = 0.6?

**Rationale**:
- Too low (0.4): Generates fixes with weak evidence (risky)
- Too high (0.8): Rarely generates fixes (not helpful)
- 0.6: Balanced - requires moderate evidence strength

**Tunable**: Can be made configurable in future versions

---

### Why Dry-Run Only (No Auto-Apply)?

**Safety-Critical Decision**:
- Automatically applying code changes is dangerous
- User should review and approve all changes
- Builds trust in the system
- Easier to debug if something goes wrong

**Trade-off**: Less automated, but much safer

---

### Why Local LLM (Ollama) Instead of Cloud APIs?

**Pros**:
- ✅ Zero cost (no API fees)
- ✅ Privacy (no data sent to third parties)
- ✅ Works offline
- ✅ Fast for small models
- ✅ No rate limits

**Cons**:
- ❌ Requires user to install Ollama
- ❌ Limited model choice compared to cloud
- ❌ Hardware requirements (GPU recommended)

**Decision**: Local-first for privacy and cost, but can add cloud provider support later

---

## Future Enhancements

### Planned Improvements

#### 1. **Plugin System**
```python
# Allow users to register custom agents
opspilot.register_agent("my_custom_agent", MyAgentClass)

# Allow custom evidence collectors
opspilot.register_tool("my_evidence_tool", my_tool_function)
```

#### 2. **Multi-LLM Support**
```python
# Support OpenAI, Anthropic, Google, etc.
opspilot analyze --provider openai --model gpt-4
opspilot analyze --provider anthropic --model claude-3
```

#### 3. **Web API Layer**
```python
# FastAPI endpoint
POST /api/analyze
{
  "project_path": "/path/to/project",
  "options": {
    "confidence_threshold": 0.7
  }
}
```

#### 4. **Feedback Loop (Self-Improvement)**
```python
# Agent can re-run if confidence is low
while state.confidence < 0.6 and state.iteration < max_iterations:
    state = collect_more_evidence(state)
    state = verifier_node(state)
```

#### 5. **Metrics & Monitoring**
- Track success rate of hypotheses
- Measure confidence accuracy
- Monitor LLM response times
- Log all decisions for audit trail

#### 6. **Advanced Evidence Collection**
- API endpoint testing
- Database query analysis
- Network connectivity checks
- Resource usage metrics

#### 7. **Domain-Specific Agents**
- PostgreSQL expert agent
- MongoDB expert agent
- Kubernetes expert agent
- AWS/Cloud infrastructure agent

---

## Summary

OpsPilot's architecture is designed for:
- ✅ **Safety**: Dry-run only, evidence-based decisions
- ✅ **Modularity**: Easy to extend with new agents/tools
- ✅ **Transparency**: Clear state transitions, confidence scores
- ✅ **Privacy**: Local-first LLM integration
- ✅ **Reliability**: Robust error handling, timeouts, fallbacks

The multi-agent pattern provides a clean, maintainable foundation for building intelligent DevOps automation tools.

---

**For more details, see:**
- [README.md](README.md) - User guide and quick start
- [Contributing Guidelines](CONTRIBUTING.md) *(coming soon)*
- [API Documentation](docs/api.md) *(coming soon)*
